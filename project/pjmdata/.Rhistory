mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
data <- scale(data, center = mean, scale = std)
# Listing 6.33 Generator yielding timeseries samples and their targets
generator <- function(data, lookback, delay, min_index, max_index,
shuffle = FALSE, batch_size = 128, step = 6) {
if (is.null(max_index)) max_index <- nrow(data) - delay - 1
i <- min_index + lookback
function() {
if (shuffle) {
rows <- sample(c((min_index+lookback):max_index), size = batch_size)
} else {
if (i + batch_size >= max_index)
i <<- min_index + lookback
rows <- c(i:min(i+batch_size, max_index))
i <<- i + length(rows)
}
samples <- array(0, dim = c(length(rows),
lookback / step,
dim(data)[[-1]]))
targets <- array(0, dim = c(length(rows)))
for (j in 1:length(rows)) {
indices <- seq(rows[[j]] - lookback, rows[[j]],
length.out = dim(samples)[[2]])
samples[j,,] <- data[indices,]
targets[[j]] <- data[rows[[j]] + delay,2]
}
list(samples, targets)
}
}
# Listing 6.34 Preparing the training, validation, and test generators
library(keras)
lookback <- 1440
step <- 6
delay <- 144
batch_size <- 128
train_gen <- generator(
data,
lookback = lookback,
delay = delay,
min_index = 1,
max_index = 200000,
shuffle = TRUE,
step = step,
batch_size = batch_size
)
val_gen = generator(
data,
lookback = lookback,
delay = delay,
min_index = 200001,
max_index = 300000,
step = step,
batch_size = batch_size
)
test_gen <- generator(
data,
lookback = lookback,
delay = delay,
min_index = 300001,
max_index = NULL,
step = step,
batch_size = batch_size
)
val_steps <- (300000 - 200001 - lookback) / batch_size
test_steps <- (nrow(data) - 300001 - lookback) / batch_size
# Listing 6.35 Computing the common-sense baseline MAE
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
# Listing 6.36 Converting the MAE back to a Celsius error
celsius_mae <- 0.29 * std[[2]]
model <- keras_model_sequential() %>%
layer_flatten(input_shape = c(lookback / step, dim(data)[-1])) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 1)
install_keras()
install.packages("codetools")
install.packages("PerformanceAnalytics")
library("rugarch", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages("class")
install.packages("JuliaCall")
install.packages("tibble")
.libPaths()
install.packages("dynlm")
install.packages(c("BH", "git2r"))
0.5 / (sqrt(5))
-10(0.517 * 0.436)
-10*(0.517 * 0.436)
-10*(0.517 * 0.047)
10000^2
10^8
2*1000*5000
10^7
2*1000*10000
20^7
2*10^7
2*5000*10000
10^8
2*1000*5000
10^6*(0.2497) + 5*10^6*0.2459 + 10^8*0.0448 + 10^7*-2.2541 + 2*10^7*-0.2430 + 10^8*-0.2049
10^6*(0.2497) + 5*10^6*(0.2459) + 10^8*(0.0448) + 10^7*(-2.2541) + 2*10^7*(-0.2430) + 10^8*(-0.2049)
(10^6)*(0.2497) + (5*10^6)*(0.2459) + (10^8)*(0.0448) + (10^7)*(-2.2541) + (2*10^7)*(-0.2430) + (10^8)*(-0.2049)
5*10^6
5000^2
(10^6)*(0.2497) + (2.5*10^7)*(0.2459) + (10^8)*(0.0448) + (10^7)*(-2.2541) + (2*10^7)*(-0.2430) + (10^8)*(-0.2049)
10000^2
2*1000*5000
10^7
2*1000*10000
2*10^7
2*5000*10000
10^8
(10^6)*(0.2497) + (2.5*10^7)*(0.2459) + (10^8)*(0.0448) + (10^7)*(-2.2541) + (2*10^7)*(-0.2430) + (10^8)*(-0.2049)
((10^6)*(0.2497)) + ((2.5*10^7)*(0.2459)) + ((10^8)*(0.0448)) + ((10^7)*(-2.2541)) + ((2*10^7)*(-0.2430)) + ((10^8)*(-0.2049))
5000^2
2.5*10^7
10000^2
10^8
2*1000*5000
10^7
2*1000*10000
2*10^7
(10^6)*(0.2497) + (2.5*10^7)*(0.2459) + (10^8)*(0.0448) + (10^7)*(-2.2541) + (2*10^7)*(-0.2430) + (10^8)*(-0.2049)
expression(\frac{2}{4})
install.packages("tikzDevice")
expression(u, 2, u + 0:9)
plot(expression(u, 2, u + 0:9)
)
demo(plotmath)
install.packages(c("cowplot", "git2r", "rlang"))
x = -4
string(x)
as.character(x)
10^6(2.49711) + 2.5*10^7(2.45904) + 10^8(0.44791) + 10^7(-2.25412) + 2*10^7(-0.24299) + 10^8(-0.20492)
10^6*(2.49711) + 2.5*10^7*(2.45904) + 10^8*(0.44791) + 10^7*(-2.25412) + 2*10^7*(-0.24299) + 10^8*(-0.20492)
install.packages(c("curl", "dbplyr", "rsconnect", "rstudioapi", "tinytex"))
install.packages(c("beginr", "clipr", "colorspace", "data.table", "psych", "tibble"))
library("forecast", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages(c("forecast", "rugarch"))
install.packages("tidyverse")
install.packages(c("purrr", "ggplot2", "dplyr", "readr", "tibble", "tidyr"))
install.packages(c("data.table", "ISLR", "openintro", "curl", "cowplot"))
install.packages(c("zoo", "xts", "tseries", "tidyselect", "tufte", "rticle", "zip", "TTR"))
install.packages("rticles")
install.packages(c("glmnet", "hash", "hashmap", "keras", "knitr", "Lahman", "Rcpp"))
install.packages(c("reshape2", "rethinking", "rmarkdown", "rmgarch", "rstan", "RUnit", "shiny"))
dir.create("~/Downloads/jena_climate", recursive = TRUE)
download.file(
"https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip",
"~/Downloads/jena_climate/jena_climate_2009_2016.csv.zip"
)
u
unzip(
"~/Downloads/jena_climate/jena_climate_2009_2016.csv.zip",
exdir = "~/Downloads/jena_climate"
)
library(tibble)
library(readr)
data_dir <- "~/Downloads/jena_climate"
fname <- file.path(data_dir, "jena_climate_2009_2016.csv")
data <- read_csv(fname)
glimpse(data)
glimpse(data)
library(ggplot2)
ggplot(data, aes(x = 1:nrow(data), y = `T (degC)`)) + geom_line()
ggplot(data[1:1440,], aes(x = 1:1440, y = `T (degC)`)) + geom_line()
sequence_generator <- function(start) {
value <- start - 1
function() {
value <<- value + 1
value
}
}
gen <- sequence_generator(10)
gen()
gen()
gen()
gen()
gen()
gen()
gen()
gen()
gen()
gen()
gen()
gen()
train_data <- data[1:200000,]
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
data <- scale(data, center = mean, scale = std)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
dir.create("~/Downloads/jena_climate", recursive = TRUE)
library(tibble)
library(readr)
data_dir <- "~/Downloads/jena_climate"
fname <- file.path(data_dir, "jena_climate_2009_2016.csv")
data <- read_csv(fname)
glimpse(data)
li
ibrary(ggplot2)
library(ggplot2)
ggplot(data, aes(x = 1:nrow(data), y = `T (degC)`)) + geom_line()
ggplot(data[1:1440,], aes(x = 1:1440, y = `T (degC)`)) + geom_line()
data <- data.matrix(data[,-1])
train_data <- data[1:200000,]
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
data <- scale(data, center = mean, scale = std)
generator <- function(data, lookback, delay, min_index, max_index,
shuffle = FALSE, batch_size = 128, step = 6) {
if (is.null(max_index))
max_index <- nrow(data) - delay - 1
i <- min_index + lookback
function() {
if (shuffle) {
rows <- sample(c((min_index+lookback):max_index), size = batch_size)
} else {
if (i + batch_size >= max_index)
i <<- min_index + lookback
rows <- c(i:min(i+batch_size-1, max_index))
i <<- i + length(rows)
}
samples <- array(0, dim = c(length(rows),
lookback / step,
dim(data)[[-1]]))
targets <- array(0, dim = c(length(rows)))
for (j in 1:length(rows)) {
indices <- seq(rows[[j]] - lookback, rows[[j]] - 1,
length.out = dim(samples)[[2]])
samples[j,,] <- data[indices,]
targets[[j]] <- data[rows[[j]] + delay,2]
}
list(samples, targets)
}
}
lookback <- 1440
step <- 6
delay <- 144
batch_size <- 128
train_gen <- generator(
data,
lookback = lookback,
delay = delay,
min_index = 1,
max_index = 200000,
shuffle = TRUE,
step = step,
batch_size = batch_size
)
val_gen = generator(
data,
lookback = lookback,
delay = delay,
min_index = 200001,
max_index = 300000,
step = step,
batch_size = batch_size
)
test_gen <- generator(
data,
lookback = lookback,
delay = delay,
min_index = 300001,
max_index = NULL,
step = step,
batch_size = batch_size
)
# This is how many steps to draw from `val_gen`
# in order to see the whole validation set:
val_steps <- (300000 - 200001 - lookback) / batch_size
# This is how many steps to draw from `test_gen`
# in order to see the whole test set:
test_steps <- (nrow(data) - 300001 - lookback) / batch_size
mean(abs(preds - targets))
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
install.packages("magrittr")
install.packages("magrittr")
install.packages("magrittr")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
mean(abs(preds - targets))
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
#c(samples, targets) %<-% val_gen()
c(samples, targets) %<% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
#c(samples, targets) %<-% val_gen()
c(samples, targets) <- val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
val_gen()
c(samples, targets) %<-% val_gen()
c(samples, targets) %<% val_gen()
c(samples, targets) <- val_gen()
c(samples, targets) %<-% val_gen()
val_gen() %>% c(samples, targets)
library(tidyverse)
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
library(magrittr)
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(tibble)
library(readr)
data_dir <- "~/Downloads/jena_climate"
fname <- file.path(data_dir, "jena_climate_2009_2016.csv")
data <- read_csv(fname)
glimpse(data)
library(ggplot2)
ggplot(data, aes(x = 1:nrow(data), y = `T (degC)`)) + geom_line()
ggplot(data[1:1440,], aes(x = 1:1440, y = `T (degC)`)) + geom_line()
data <- data.matrix(data[,-1])
train_data <- data[1:200000,]
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
data <- scale(data, center = mean, scale = std)
generator <- function(data, lookback, delay, min_index, max_index,
shuffle = FALSE, batch_size = 128, step = 6) {
if (is.null(max_index))
max_index <- nrow(data) - delay - 1
i <- min_index + lookback
function() {
if (shuffle) {
rows <- sample(c((min_index+lookback):max_index), size = batch_size)
} else {
if (i + batch_size >= max_index)
i <<- min_index + lookback
rows <- c(i:min(i+batch_size-1, max_index))
i <<- i + length(rows)
}
samples <- array(0, dim = c(length(rows),
lookback / step,
dim(data)[[-1]]))
targets <- array(0, dim = c(length(rows)))
for (j in 1:length(rows)) {
indices <- seq(rows[[j]] - lookback, rows[[j]] - 1,
length.out = dim(samples)[[2]])
samples[j,,] <- data[indices,]
targets[[j]] <- data[rows[[j]] + delay,2]
}
list(samples, targets)
}
}
lookback <- 1440
step <- 6
delay <- 144
batch_size <- 128
train_gen <- generator(
data,
lookback = lookback,
delay = delay,
min_index = 1,
max_index = 200000,
shuffle = TRUE,
step = step,
batch_size = batch_size
)
val_gen = generator(
data,
lookback = lookback,
delay = delay,
min_index = 200001,
max_index = 300000,
step = step,
batch_size = batch_size
)
test_gen <- generator(
data,
lookback = lookback,
delay = delay,
min_index = 300001,
max_index = NULL,
step = step,
batch_size = batch_size
)
# This is how many steps to draw from `val_gen`
# in order to see the whole validation set:
val_steps <- (300000 - 200001 - lookback) / batch_size
# This is how many steps to draw from `test_gen`
# in order to see the whole test set:
test_steps <- (nrow(data) - 300001 - lookback) / batch_size
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
val_gen() %>% c(samples, targets)
c(samples, targets) %<-% val_gen()
val_gen()
c(samples, targets) <- val_gen()
samples, targets <- val_gen()
c(samples, targets) <- val_gen()
c(samples, targets) %<-% val_gen()
library(keras)
evaluate_naive_method <- function() {
batch_maes <- c()
for (step in 1:val_steps) {
c(samples, targets) %<-% val_gen()
preds <- samples[,dim(samples)[[2]],2]
mae <- mean(abs(preds - targets))
batch_maes <- c(batch_maes, mae)
}
print(mean(batch_maes))
}
evaluate_naive_method()
celsius_mae <- evaluate_naive_method() * std[[2]]
Sys.info()
R.version
capabilities()
citation()
?copyright
capabilities()
hip <- read.table("http://astrostatistics.psu.edu/datasets/HIP_star.dat",
header=T,fill=T)
dim(hip)
names(hip)
hip[1,]
hip[1,20:7]
hip[1:20,7]
sum(hip[,3])
source('~/Dropbox/w2018/bus699/PJM/cis696_project_PJM.R')
View(garchfit)
inforcriteria
?inforcriteria
infocriteria(garchfit)
?infocriteria
View(garchfit)
show(garchspec)
autoplot(sigma(garchfit))
autoplot(mean(garchfit))
mean(garchfit)
which(is.na(sigma(garchfit)))
head(sigma(garchfit))
is.na(sigma(garchfit))
View(garchfit)
garchfit@fit[["sigma"]]
View(garchfit@fit[["sigma"]])
mean(garchfit@fit[["sigma"]])
mean(sigma(garchfit))
mean(garchfit)
autoplot(fitted(garchfit))
install.packages("lmtest")
